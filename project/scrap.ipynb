{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Best: 0.800507 using {'batch_size': 10, 'epochs': 20, 'n_hidden': 2, 'nodes': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual\n",
    "\n",
    "def create_keras_model(input_dim=11, output_dim=5, n_hidden=4, name='model'):\n",
    "    '''\n",
    "    How to call:\n",
    "    myModel = create_keras_model(n_features, n_classes, nodes=5, n=4, name='model')\n",
    "    '''\n",
    "\n",
    "    # define input layer\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # list to hold all the hidden layers\n",
    "    hidden_layers = []\n",
    "\n",
    "    # create the hidden layers\n",
    "\n",
    "    # if it's the first hidden layer, connect it to the inputs\n",
    "    hidden_layers.append(Dense(units=6, activation='relu', kernel_initializer='random_normal')(inputs))\n",
    "\n",
    "    # otherwise, connect it to the previous hidden layer\n",
    "    hidden_layers.append(Dense(units=5, activation='relu', kernel_initializer='random_normal')(hidden_layers[-1]))\n",
    "            \n",
    "    # create the final hidden layer, connected to all previous hidden layers\n",
    "    final_hidden = Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(concatenate(hidden_layers))\n",
    "\n",
    "    # create output layer connected to the final hidden layer\n",
    "    outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model0 = create_keras_model(n_features, n_classes, nodes=5, n_hidden=4, name='model')\n",
    "model0.summary()\n",
    "plot_model(model0, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 21, 41]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 50, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_keras_model(input_dim, output_dim, nodes=5, n_hidden=1, name='model'):\n",
    "#     '''\n",
    "#     How to call:\n",
    "#     myModel = create_keras_model(n_features, n_classes, nodes=5, n=1, name='model')\n",
    "#     '''\n",
    "#     # Create model\n",
    "#     model = Sequential(name=name)\n",
    "#     model.add(Dense(units=nodes,\n",
    "#                     input_dim=input_dim,\n",
    "#                     activation='relu',\n",
    "#                     kernel_initializer='random_normal'\n",
    "#                    )\n",
    "#              )\n",
    "#     # add HIDDEN layers to the network:\n",
    "#     for i in range(n_hidden):\n",
    "#         model.add(Dense(units=nodes,\n",
    "#                         activation='relu',\n",
    "#                         kernel_initializer='random_normal'\n",
    "#                        )\n",
    "#                  )\n",
    "#     # OUTPUT layer:\n",
    "#     model.add(Dense(output_dim, \n",
    "#                     activation='softmax', #  sigmoid\n",
    "#                    )\n",
    "#              )\n",
    "    \n",
    "#     model.compile(optimizer='adam', #  sgd\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy']\n",
    "#                  )\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# def create_keras_model(input_dim, output_dim, nodes=5, n_hidden=4, name='model'):\n",
    "#     '''\n",
    "#     How to call:\n",
    "#     myModel = create_keras_model(n_features, n_classes, nodes=5, n=4, name='model')\n",
    "#     '''\n",
    "\n",
    "#     # define input layer\n",
    "#     inputs = Input(shape=(input_dim,))\n",
    "\n",
    "#     # list to hold all the hidden layers\n",
    "#     hidden_layers = []\n",
    "\n",
    "#     # create the hidden layers\n",
    "#     for i in range(n_hidden):\n",
    "#         if i == 0:\n",
    "#             # if it's the first hidden layer, connect it to the inputs\n",
    "#             hidden_layers.append(Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(inputs))\n",
    "#         else:\n",
    "#             # otherwise, connect it to the previous hidden layer\n",
    "#             hidden_layers.append(Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(hidden_layers[-1]))\n",
    "            \n",
    "#     # create the final hidden layer, connected to all previous hidden layers\n",
    "#     final_hidden = Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(concatenate(hidden_layers))\n",
    "\n",
    "#     # create output layer connected to the final hidden layer\n",
    "#     outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "#     # create model\n",
    "#     model = Model(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# def create_keras_model(input_dim=11, output_dim=5, nodes=5, n_hidden=4, name='model'):\n",
    "#     '''\n",
    "#     How to call:\n",
    "#     myModel = create_keras_model(n_features, n_classes, nodes=5, n=4, name='model')\n",
    "#     '''\n",
    "\n",
    "#     # define input layer\n",
    "#     inputs = Input(shape=(input_dim,))\n",
    "\n",
    "#     # list to hold all the hidden layers\n",
    "#     hidden_layers = []\n",
    "\n",
    "#     # create the hidden layers\n",
    "#     for i in range(n_hidden-1):\n",
    "#         if i == 0:\n",
    "#             # if it's the first hidden layer, connect it to the inputs\n",
    "#             hidden_layers.append(Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(inputs))\n",
    "#         else:\n",
    "#             # otherwise, connect it to the previous hidden layer\n",
    "#             hidden_layers.append(Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(hidden_layers[-1]))\n",
    "            \n",
    "#     # create the final hidden layer, connected to all previous hidden layers\n",
    "#     final_hidden = Dense(units=nodes, activation='relu', kernel_initializer='random_normal')(concatenate(hidden_layers))\n",
    "\n",
    "#     # create output layer connected to the final hidden layer\n",
    "#     outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "#     # create model\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model0.metrics_names\n",
    "\n",
    "\n",
    "# score = model0.evaluate(X_test, Y_test, verbose=1)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2, figsize=(9, 8))\n",
    "\n",
    "# val_accurady = model0firstfit.history['val_accuracy']\n",
    "# val_loss = model0firstfit.history['val_loss']\n",
    "# ax1.plot(val_accurady)\n",
    "# ax2.plot(val_loss)\n",
    "    \n",
    "# ax1.set_ylabel('Validation Accuracy')\n",
    "# ax2.set_ylabel('Validation Loss')\n",
    "# ax2.set_xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_keras_model(input_dim=11, output_dim=5, hidden_nodes=[5, 10, 15], name='model'):\n",
    "#     '''\n",
    "#     How to call:\n",
    "#     myModel = create_keras_model(n_features, n_classes, hidden_nodes=[5, 10, 15], name='model')\n",
    "#     '''\n",
    "#     np.random.seed(42)\n",
    "#     tf.random.set_seed(42)\n",
    "\n",
    "#     # define input layer\n",
    "#     inputs = Input(shape=(input_dim,))\n",
    "\n",
    "#     # list to hold all the hidden layers\n",
    "#     hidden_layers = []\n",
    "\n",
    "#     # create the hidden layers\n",
    "#     for i in range(len(hidden_nodes)):\n",
    "#         if i == 0:\n",
    "#             # if it's the first hidden layer, connect it to the inputs\n",
    "#             hidden_layers.append(Dense(units=hidden_nodes[i], activation='relu', kernel_initializer='random_normal')(inputs))\n",
    "#         else:\n",
    "#             # otherwise, connect it to the previous hidden layer\n",
    "#             hidden_layers.append(Dense(units=hidden_nodes[i], activation='relu', kernel_initializer='random_normal')(hidden_layers[-1]))\n",
    "            \n",
    "#     # create the final hidden layer, connected to all previous hidden layers\n",
    "#     final_hidden = Dense(units=hidden_nodes[-1], activation='relu', kernel_initializer='random_normal')(concatenate(hidden_layers))\n",
    "\n",
    "#     # create output layer connected to the final hidden layer\n",
    "#     outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "#     # create model\n",
    "#     model = Model(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model0 = create_keras_model(n_features, n_classes, hidden_nodes=[6, 5, 5, 10], name='model')\n",
    "# model0.summary()\n",
    "# plot_model(model0, show_shapes=True)\n",
    "\n",
    "\n",
    "# COMPRSSED MODEL\n",
    "\n",
    "def create_keras_model(input_dim=11, output_dim=5, hidden_nodes=[[5, 2], [10, 4], [15, 8]]):\n",
    "    '''\n",
    "    How to call:\n",
    "    myModel = create_keras_model(n_features, n_classes, hidden_nodes=[[5, 2], [10, 4], [15, 8]])\n",
    "    '''\n",
    "\n",
    "    # define input layer\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # list to hold all the hidden layers\n",
    "    hidden_layers = []\n",
    "    compressed_layers = []\n",
    "\n",
    "    # create the hidden layers\n",
    "    for i in range(len(hidden_nodes)):\n",
    "        if i == 0:\n",
    "            # if it's the first hidden layer, connect it to the inputs\n",
    "            hidden_layers.append(Dense(units=hidden_nodes[i][0], activation='relu', kernel_initializer='random_normal')(inputs))\n",
    "        else:\n",
    "            # otherwise, connect it to the previous hidden layer\n",
    "            hidden_layers.append(Dense(units=hidden_nodes[i][0], activation='relu', kernel_initializer='random_normal')(hidden_layers[-1]))\n",
    "        \n",
    "        # create compression layer\n",
    "        compressed_layers.append(Dense(units=hidden_nodes[i][1], activation='relu', kernel_initializer='random_normal')(hidden_layers[-1]))\n",
    "\n",
    "    # create the final hidden layer, connected to all compression layers\n",
    "    final_hidden = Dense(units=hidden_nodes[-1][1], activation='relu', kernel_initializer='random_normal')(concatenate(compressed_layers))\n",
    "\n",
    "    # create output layer connected to the final hidden layer\n",
    "    outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model0 = create_keras_model(n_features, n_classes, hidden_nodes=[[6, 3], [5, 3], [5, 4]])\n",
    "model0.summary()\n",
    "plot_model(model0, show_shapes=True)\n",
    "\n",
    "model0firstfit = model0.fit(X_train, Y_train, batch_size=32, epochs=400, verbose=0, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_keras_model(input_dim=11, output_dim=5, hidden_nodes=[5, 10, 15], learning_rate=0.001, regularization_factor=0.01, early_stopping_monitor='val_loss', name='model'):\n",
    "    '''\n",
    "    How to call:\n",
    "    myModel = create_keras_model(n_features, n_classes, hidden_nodes=[5, 10, 15], learning_rate=0.001, regularization_factor=0.01, early_stopping_monitor='val_loss', name='model')\n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # define input layer\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # list to hold all the hidden layers\n",
    "    hidden_layers = []\n",
    "\n",
    "    # create the hidden layers\n",
    "    for i in range(len(hidden_nodes)):\n",
    "        if i == 0:\n",
    "            # if it's the first hidden layer, connect it to the inputs\n",
    "            hidden_layers.append(Dense(units=hidden_nodes[i], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(inputs))\n",
    "        else:\n",
    "            # otherwise, connect it to the previous hidden layer\n",
    "            hidden_layers.append(Dense(units=hidden_nodes[i], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(hidden_layers[-1]))\n",
    "            \n",
    "    # create the final hidden layer, connected to all previous hidden layers\n",
    "    final_hidden = Dense(units=hidden_nodes[-1], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(concatenate(hidden_layers))\n",
    "\n",
    "    # create output layer connected to the final hidden layer\n",
    "    outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=name)\n",
    "\n",
    "    # define optimizer with the given learning rate\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Define early stopping callback\n",
    "    early_stopping_callback = EarlyStopping(monitor=early_stopping_monitor, patience=3)\n",
    "\n",
    "    return model, early_stopping_callback\n",
    "\n",
    "model0, early_stopping = create_keras_model(n_features, n_classes, hidden_nodes=[6, 5, 5, 10], learning_rate=0.001, regularization_factor=0.01, early_stopping_monitor='val_loss', name='model')\n",
    "model0.summary()\n",
    "plot_model(model0, show_shapes=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the model with early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "model0firstfit = model0.fit(X_train, Y_train, validation_data=(X_test, Y_test), verbose=0, epochs=500, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(input_dim=11, output_dim=5, hidden_nodes=[[6, 3], [5, 3], [5, 4]], \n",
    "                       optimizer='adam', learning_rate=0.001, regularization_factor=0.01, \n",
    "                       early_stopping_monitor='val_loss', early_stop_patience=3, batch_size=32):\n",
    "    '''\n",
    "    How to call:\n",
    "    model_name = create_keras_model(n_features, n_classes, hidden_nodes=[[5, 2], [10, 4], [15, 8]], \n",
    "                                    optimizer='adam', learning_rate=0.001, regularization_factor=0.01, \n",
    "                                    early_stopping_monitor='val_loss', early_stopping_patience=3, batch_size=32)\n",
    "    '''\n",
    "\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # input layer\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    # lists to hold hidden layers\n",
    "    hidden_layers = []\n",
    "    compressed_layers = []\n",
    "\n",
    "    # create hidden layers\n",
    "    for i in range(len(hidden_nodes)):\n",
    "        if i == 0:\n",
    "            # if it's the first hidden layer, connect it to the inputs\n",
    "            hidden_layers.append(Dense(units=hidden_nodes[i][0], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(inputs))\n",
    "        else:\n",
    "            # otherwise, connect it to the previous hidden layer\n",
    "            hidden_layers.append(Dense(units=hidden_nodes[i][0], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(hidden_layers[-1]))\n",
    "        \n",
    "        # compression layer\n",
    "        compressed_layers.append(Dense(units=hidden_nodes[i][1], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(hidden_layers[-1]))\n",
    "\n",
    "    # final hidden layer, connected to all compression layers\n",
    "    final_hidden = Dense(units=hidden_nodes[-1][1], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(concatenate(compressed_layers))\n",
    "\n",
    "    # output layer, connected to final hidden layer\n",
    "    outputs = Dense(output_dim, activation='softmax')(final_hidden)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # define optimizer with the given learning rate\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    # Define early stopping callback\n",
    "    early_stopping_callback = EarlyStopping(monitor=early_stopping_monitor, patience=early_stop_patience)\n",
    "\n",
    "    return model, early_stopping_callback\n",
    "\n",
    "model0, early_stop = create_keras_model(n_features, n_classes, hidden_nodes=[[6, 3], [5, 3], [5, 4]], \n",
    "                                        optimizer='rmsprop', learning_rate=0.001, regularization_factor=0.01, \n",
    "                                        early_stopping_monitor='val_loss', early_stop_patience=100, batch_size=64)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working y Y ?i think yea no work\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Combine the one-hot encoded columns into a single target variable\n",
    "y = np.argmax(Y, axis=1)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store evaluation results across folds\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train your model on the training set\n",
    "    # Define early stopping callback\n",
    "    early_stop0 = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    # Train the model\n",
    "    model0firstfit = model0.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1, batch_size=1, epochs=1000, callbacks=[early_stop0])\n",
    "    \n",
    "    # Test your model on the testing set\n",
    "    y_pred = model0firstfit.predict(X_test)\n",
    "    \n",
    "    # Convert the predicted probabilities to class labels\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Evaluate the model's performance on the testing set\n",
    "    accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Additional evaluation metrics or analysis\n",
    "    # ...\n",
    "    \n",
    "# Aggregate the evaluation results across folds\n",
    "mean_accuracy = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# straight up first wrong \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store evaluation results across folds\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train your model on the training set\n",
    "    # Define early stopping callback\n",
    "    early_stop0 = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    # Train the model\n",
    "    model0firstfit = model0.fit(X_train, Y_train, validation_data=(X_test, Y_test), verbose=1, batch_size=1, epochs=1000, callbacks=[early_stop0])\n",
    "    \n",
    "    # Test your model on the testing set\n",
    "    y_pred = model0firstfit.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model's performance on the testing set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    # Additional evaluation metrics or analysis\n",
    "    # ...\n",
    "    \n",
    "# Aggregate the evaluation results across folds\n",
    "mean_accuracy = np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidental convergence to 4 nodes\n",
    "\n",
    "    # # create hidden layers\n",
    "    # for i in range(len(hidden_nodes)):\n",
    "    #     if i == 0:\n",
    "    #         # if it's the first hidden layer, connect it to the inputs\n",
    "    #         hidden_layers.append(Dense(units=hidden_nodes[i][0], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(inputs))\n",
    "    #     else:\n",
    "    #         # otherwise, connect it to the previous hidden layer\n",
    "    #         hidden_layers.append(Dense(units=hidden_nodes[i][0], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(hidden_layers[-1]))\n",
    "        \n",
    "    #     # compression layer\n",
    "    #     compressed_layers.append(Dense(units=hidden_nodes[i][1], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(hidden_layers[-1]))\n",
    "\n",
    "    # # final hidden layer, connected to all compression layers\n",
    "    # final_hidden = Dense(units=hidden_nodes[-1][1], activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(regularization_factor))(concatenate(compressed_layers))\n",
    "\n",
    "    # # output layer, connected to final hidden layer\n",
    "    # outputs = Dense(output_dim, activation='softmax')(final_hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
